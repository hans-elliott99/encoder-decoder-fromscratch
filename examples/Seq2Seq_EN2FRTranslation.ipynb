{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGM/xpxMaEe8mr3JJ2/zRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hans-elliott99/encoder-decoder-fromscratch/blob/main/examples/Seq2Seq_EN2FRTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import unicodedata\n",
        "import string\n",
        "from typing import Union\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "# Model/Train Helpers\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# PyTorch\n",
        "import torch"
      ],
      "metadata": {
        "id": "-l3Y67HErBat"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4pEfoLQwQ9r",
        "outputId": "a8bb9667-a79a-4b0e-96c9-eca47c902e7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSNM_9Y_stX1",
        "outputId": "a4b2b26f-c888-4007-a02f-9c274b280a99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "0q47D8-UwYQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grad_flow_basic(raw_parameters : list, param_names : list=None, y_ax_max=\"max_average\"):\n",
        "    '''\n",
        "    Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Provide the list of raw model parameters. Optionally provide list of names matching param order.\n",
        "    y_ax_max is the y axis limit and is either \"max_average\" or \"mean_average\"\n",
        "    Adapted from source: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/10\n",
        "    '''\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "    for n, p in enumerate(raw_parameters):\n",
        "        if(p.requires_grad) & (p.grad is not None): #and (\"bias\" not in n):\n",
        "            layers.append(str(n))\n",
        "            ave_grads.append(p.grad.abs().mean().item())\n",
        "            max_grads.append(p.grad.abs().max().item())\n",
        "\n",
        "    xticks = range(0,len(ave_grads), 1)\n",
        "    y_min = min(ave_grads)\n",
        "    y_max = max(ave_grads)\n",
        "    if y_ax_max == \"mean_average\":\n",
        "        y_max = (sum(ave_grads)/len(ave_grads))\n",
        "    if param_names is not None:\n",
        "        for x_ix in xticks:\n",
        "            plt.text(x_ix, y_max/3, s=param_names[x_ix], rotation=90)\n",
        "\n",
        "    plt.bar(range(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(range(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(xticks, layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = y_min, top=y_max) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
      ],
      "metadata": {
        "id": "O8fLJBWGrOBG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_to_ch_data(eng, fra, stoi, stop_char:str, device):\n",
        "    \"\"\"\n",
        "    Converts words to character-level data.\n",
        "    \"\"\"\n",
        "    assert len(eng)==len(fra)\n",
        "    # Data\n",
        "    ## block_size = context length: how many chars do we use to predict the next?\n",
        "    X, Y = [], []\n",
        "    for en, fr in zip(eng, fra):\n",
        "        \n",
        "        # diff = len(fr) - len(en)\n",
        "        # if diff > 0:\n",
        "        #     add_to_en = abs(diff)\n",
        "        #     add_to_fr = 0\n",
        "        # elif diff < 0:\n",
        "        #     add_to_en = 0\n",
        "        #     add_to_fr = abs(diff)\n",
        "        # else:\n",
        "        #     add_to_en = 0\n",
        "        #     add_to_fr = 0\n",
        "\n",
        "        english_ix, french_ix = [], []\n",
        "        for ch in en:\n",
        "            english_ix.append(stoi[ch])\n",
        "        english_ix.append(stoi[stop_char])\n",
        "        # english_ix += [stoi[stop_char]] * add_to_en\n",
        "\n",
        "        for ch in fr:\n",
        "            french_ix.append(stoi[ch])\n",
        "        french_ix.append(stoi[stop_char])\n",
        "        # french_ix += [stoi[stop_char]] * add_to_fr\n",
        "\n",
        "        X.append(torch.tensor(english_ix, device=device))\n",
        "        Y.append(torch.tensor(french_ix, device=device))\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def words_to_word_data(eng, fra, stoi, stop_char:str, device, keep_punct=\"\"):\n",
        "    \"\"\"\n",
        "    Converts words to word-level data.\n",
        "    \"\"\"\n",
        "    assert len(eng)==len(fra)\n",
        "    remove_punct = ''.join([p for p in string.punctuation if p not in keep_punct]) ##remove all punct except...\n",
        "    # Data\n",
        "    X, Y = [], []\n",
        "    for en, fr in zip(eng, fra):\n",
        "        # remove unwanted punctuation\n",
        "        en = ''.join([c for c in en if c not in remove_punct]).lower()\n",
        "        fr = ''.join([c for c in fr if c not in remove_punct]).lower()\n",
        "\n",
        "        # split phrases into words\n",
        "        english_ix, french_ix = [], []\n",
        "        for wd in en.split():\n",
        "            english_ix.append(stoi[wd])\n",
        "        english_ix.append(stoi[stop_char])\n",
        "\n",
        "        for wd in fr.split():\n",
        "            french_ix.append(stoi[wd])\n",
        "        french_ix.append(stoi[stop_char])\n",
        "\n",
        "        X.append(torch.tensor(english_ix, device=device))\n",
        "        Y.append(torch.tensor(french_ix, device=device))\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "\n",
        "def split_samples(inputs, labels, frac=0.8, seed=123):\n",
        "    \"Split x and y tensors (inputs and labels) into train and test sets\"\n",
        "    \n",
        "    assert len(inputs)==len(labels), f\"len(inputs) {len(inputs)} does not match len(labels) {len(labels)}\"\n",
        "    # generate a list of indices to exclude. Turn in into a set for O(1) lookup time\n",
        "    random.seed(seed)\n",
        "    indx = list(set(random.sample(list(range(len(inputs))), int(frac*len(inputs)))))\n",
        "\n",
        "    x_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
        "    x_mask[indx] = True\n",
        "\n",
        "    y_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
        "    y_mask[indx] = True\n",
        "\n",
        "    train_x = inputs[x_mask]\n",
        "    train_y = labels[y_mask]\n",
        "\n",
        "    test_x = inputs[~x_mask]\n",
        "    test_y = labels[~y_mask]\n",
        "\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "metadata": {
        "id": "Bow6RlnKsK9w"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_data(file_path, max_english_chars, max_french_chars):\n",
        "    english, french = [],[]\n",
        "\n",
        "    matches = [\"(\", \"‽\", \"…\", \"€\"]\n",
        "    with open(file_path, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            line = line.rstrip()\n",
        "            line = line.replace(u\"\\u202f\", \" \")\n",
        "            line = line.replace(u\"\\u3000\", \" \")\n",
        "            line = line.replace(u\"\\u2000\", \" \")\n",
        "            line = line.replace(u\"\\u200b\", \" \")\n",
        "            line = line.replace(u\"\\xa0\", \" \")\n",
        "            line = line.replace(u\"\\xad\", \" \")\n",
        "            line = line.replace(u\"\\u2009\", \" \")\n",
        "            line = line.replace(\"ú\", \"u\")\n",
        "            line = line.replace(\"–\", \"-\")\n",
        "            line = line.replace(\"а\", \"a\")\n",
        "            line = line.replace(\"‐\", \"-\")\n",
        "            line = line.replace(\"₂\", \"2\")\n",
        "            line = line.replace(\"\\'\", \"'\")\n",
        "            if any(s in line for s in matches): ##removes some edge cases\n",
        "                pass\n",
        "            else:        \n",
        "                eng, fra = line.split('\\t')\n",
        "            \n",
        "            if (len(fra)>max_french_chars) | (len(eng)>max_english_chars):\n",
        "                pass\n",
        "            else:\n",
        "                english.append(eng)\n",
        "                french.append(fra)\n",
        "    return english, french"
      ],
      "metadata": {
        "id": "63gLUhS1sXqa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "## Encoder-Decoder Network with GRUs processing the sequences"
      ],
      "metadata": {
        "id": "FUjC2tM2wbO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslGRU:\n",
        "    def __init__(self, vocab_size, \n",
        "                       enc_embed_dim, dec_embed_dim,\n",
        "                       dec_type, hidden_size, max_length,\n",
        "                       stoi_mapping, start_chr, stop_chr\n",
        "                ) -> None:\n",
        "        \"\"\"\n",
        "        Define an Encoder-Decoder network each consisting of a GRU for sequence to sequence translation.\n",
        "        n_letters = number of unique letters/characters that appear in the data.\n",
        "        embed_dim = dimension of the embedding layer\n",
        "        dec_type = \"simple\" or \"attention\"  \n",
        "        hidden_size = desired number of elements in the hidden and cell states\n",
        "        output_size = Dense layer ontop of the decoder converts last hidden state to logits of shape (output_size, 1)\n",
        "        \"\"\"\n",
        "        # Model architecture\n",
        "        self.input_size = vocab_size\n",
        "        \n",
        "        self.enc_embed_dim = enc_embed_dim\n",
        "        self.dec_embed_dim = dec_embed_dim\n",
        "        self.dec_type = dec_type\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.enc_hidden_size = hidden_size ## technically the dec hidden size has to be the same as the encoder rn\n",
        "        self.dec_hidden_size = hidden_size ##\n",
        "\n",
        "        self.output_size = vocab_size\n",
        "        \n",
        "        # Data processing\n",
        "        self.stoi = stoi_mapping\n",
        "        self.itos = {i:s for s, i in stoi_mapping.items()}\n",
        "\n",
        "        assert start_chr in stoi_mapping\n",
        "        assert stop_chr in stoi_mapping\n",
        "        self.start_chr_ix = stoi_mapping[start_chr]\n",
        "        self.stop_chr_ix = stoi_mapping[stop_chr]\n",
        "\n",
        "    def init_hidden(self) -> torch.tensor:\n",
        "        \"\"\"Initialize hidden state. Returns: hidden\"\"\"\n",
        "        hidden = torch.zeros((self.enc_hidden_size, 1), device=self.device)  #(hidden size , batch size)\n",
        "        return hidden\n",
        "\n",
        "    def init_weights(self, device, seed=123) -> None:\n",
        "        \"\"\"Initialize weight tensors for the model.\"\"\"\n",
        "        g = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "        self.device = device\n",
        "        self.params = []\n",
        "        self.param_names = []\n",
        "\n",
        "        self._init_enc_weights(g=g, device=device)\n",
        "        self._init_dec_weights(g=g, device=device)\n",
        "        \n",
        "        for p in self.params:\n",
        "            p.requires_grad = True\n",
        "\n",
        "        self.n_parameters = self._count_params()\n",
        "\n",
        "    def _init_enc_weights(self, g, device) -> None:\n",
        "        \"\"\"Initialize weight tensors for the decoder model.\"\"\"\n",
        "        std = 1.0 / np.sqrt(self.enc_hidden_size)\n",
        "        concat_size = self.enc_embed_dim + self.enc_hidden_size\n",
        "\n",
        "        self.enc_embed = (-std - std) * torch.rand((self.input_size, self.enc_embed_dim), generator=g, device=device) + std\n",
        "\n",
        "        self.enc_W_reset = (-std - std) * torch.rand((self.enc_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        self.enc_br = torch.zeros((self.enc_hidden_size, 1), device=device)\n",
        "        self.enc_W_update = (-std - std) * torch.rand((self.enc_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        self.enc_bu = torch.zeros((self.enc_hidden_size, 1), device=device)\n",
        "        self.enc_W_htilde = (-std - std) * torch.rand((self.enc_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        #self.bh = torch.zeros((self.hidden_size, 1), device=device)\n",
        "        \n",
        "        self.params += [self.enc_embed, self.enc_W_reset, self.enc_br, self.enc_W_update, self.enc_bu, self.enc_W_htilde]\n",
        "        self.param_names += ['enc_embed', 'enc_W_reset', 'enc_br', 'enc_W_update', 'enc_bu', 'enc_W_htilde']\n",
        "        \n",
        "    def _init_dec_weights(self, g, device) -> None:\n",
        "        \"\"\"Initialize weight tensors for the decoder.\"\"\"\n",
        "        std = 1.0 / np.sqrt(self.dec_hidden_size)\n",
        "        concat_size = self.dec_embed_dim + self.dec_hidden_size\n",
        "\n",
        "        if self.dec_type == \"attention\":\n",
        "            self.W_att = (-std - std) * torch.rand((self.max_length, concat_size), generator=g, device=device) + std\n",
        "            self.ba = torch.zeros((self.max_length, 1), device=device)\n",
        "            self.W_rel = (-std - std) * torch.rand((self.dec_embed_dim, concat_size), generator=g, device=device) + std\n",
        "            self.brel = torch.zeros((self.dec_embed_dim, 1), device=device)\n",
        "\n",
        "            self.params += [self.W_att, self.ba, self.W_rel, self.brel]\n",
        "            self.param_names += ['W_att', 'ba', 'W_rel', 'brel']\n",
        "\n",
        "        self.dec_embed = (-std - std) * torch.rand((self.input_size, self.dec_embed_dim), generator=g, device=device) + std\n",
        "        self.dec_W_reset = (-std - std) * torch.rand((self.dec_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        self.dec_br = torch.zeros((self.dec_hidden_size, 1), device=device)\n",
        "        self.dec_W_update = (-std - std) * torch.rand((self.dec_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        self.dec_bu = torch.zeros((self.dec_hidden_size, 1), device=device)\n",
        "        self.dec_W_htilde = (-std - std) * torch.rand((self.dec_hidden_size, concat_size), generator=g, device=device) + std\n",
        "        #self.bh = torch.zeros((self.hidden_size, 1), device=device)\n",
        "        # FC HEAD\n",
        "        self.W_h2o = (-std - std) * torch.rand((self.output_size, self.dec_hidden_size), generator=g, device=device) + std\n",
        "        self.b_h20 = torch.zeros((self.output_size, 1), device=device)\n",
        "\n",
        "        self.params += [self.dec_embed, self.dec_W_reset, self.dec_br, self.dec_W_update, self.dec_bu, self.dec_W_htilde, self.W_h2o, self.b_h20]\n",
        "        self.param_names += ['dec_embed', 'dec_W_reset', 'dec_br', 'dec_W_update', 'dec_bu', 'dec_W_htilde', 'W_h2o', 'b_h20']\n",
        "\n",
        "\n",
        "    def encoder(self, hidden_prev, x_tensor_t):\n",
        "        \"ENCODER AT STEP T\"\n",
        "        input = self.enc_embed[x_tensor_t].unsqueeze(dim=1)\n",
        "        hidden_new = self.gru(input, hidden_prev, self.enc_W_reset, self.enc_br, self.enc_W_update, self.enc_bu, self.enc_W_htilde)\n",
        "        return hidden_new\n",
        "    \n",
        "    def simple_decoder(self, context_vector, input_char_t):\n",
        "        \"DECODER AT STEP T\"\n",
        "        input = self.dec_embed[input_char_t].unsqueeze(dim=1)\n",
        "        hidden_new = self.gru(input, context_vector, self.dec_W_reset, self.dec_br, self.dec_W_update, self.dec_bu, self.dec_W_htilde)\n",
        "        \n",
        "        # run hidden state through linear layer to predict next char\n",
        "        # output = torch.softmax(self.linear(hidden_new))\n",
        "        logits = self.linear_head(hidden_new)\n",
        "        next_input_char = int(torch.argmax(logits, dim=0).item()) ##return just the index\n",
        "\n",
        "        return hidden_new, logits, next_input_char\n",
        "    \n",
        "    def attention_decoder(self, enc_outputs, prev_hidden, input_char_t):\n",
        "        \"ATTENTION DECODER AT STEP T\"\n",
        "        # embed the current character and concatenate with previous hidden state\n",
        "        embedded = self.dec_embed[input_char_t].unsqueeze(dim=1) ##shape embed_dim, 1\n",
        "        concat1 = torch.cat((embedded, prev_hidden), dim=0).to(self.device)      ##shape embed_dim+hidden_size, 1\n",
        "        # calculate attention weights by passing in the concatenation & softmaxing\n",
        "        # apply the attention vector to the context vector\n",
        "        atten = torch.nn.functional.softmax(self.linear_attention(concat1), dim=0).T ##shape 1, max_len. & enc_outputs have shape max_len, hidden_size\n",
        "        atten_weighted = (atten @ enc_outputs).squeeze(dim=0)            ##shape hidden_size\n",
        "        ## attention vector is broadcast over the entire enc output matrix (where each row is a hidden state), weighting\n",
        "\n",
        "        # concat the attention-weighted context with the input embedding and pass through a ReLU linear layer\n",
        "        concat2 = torch.cat((embedded, atten_weighted.unsqueeze(dim=1)), dim=0).to(self.device)          ##shape embed_dim+hidden_size, 1\n",
        "        gru_input = torch.nn.functional.relu(self.linear_relu(concat2))                 ##shape embed_dim, 1\n",
        "\n",
        "        # pass the attention-processed inputs into the decoder gru along with previous hidden state to generate new hidden\n",
        "        hidden_new = self.gru(gru_input, prev_hidden, self.dec_W_reset, self.dec_br, self.dec_W_update, self.dec_bu, self.dec_W_htilde)\n",
        "\n",
        "        # run hidden state through linear layer to predict next char\n",
        "        logits = self.linear_head(hidden_new)  \n",
        "        next_input_char = int(torch.argmax(logits, dim=0).item())\n",
        "        \n",
        "        return hidden_new, logits, next_input_char\n",
        "    \n",
        "    def gru(self, input, hidden,\n",
        "                  W_reset, br,\n",
        "                  W_update, bu,\n",
        "                  W_htilde\n",
        "                  ) -> torch.tensor:\n",
        "        \"\"\"One forward step in a GRU cell to update hidden state. Returns: hidden_new\"\"\"\n",
        "        # Concatenate inputs with incoming hidden state\n",
        "        concat_raw = torch.cat((input, hidden), dim=0)\n",
        "\n",
        "        # Calc reset gate and apply to hidden state to produce gated/reset hidden state\n",
        "        r_gate = torch.sigmoid(W_reset @ concat_raw + br)\n",
        "        hidden_reset = hidden * r_gate\n",
        "\n",
        "        # Concatenate inputs with gated hidden state\n",
        "        concat_gated = torch.cat((input, hidden_reset), dim=0)\n",
        "        # Calculate h tilde, the proposed new hidden state, using the gated concatenation\n",
        "        h_tilde = torch.tanh(W_htilde @ concat_gated)\n",
        "\n",
        "        # Calc update gate using the raw/ungated concatenation\n",
        "        u_gate = torch.sigmoid(W_update @ concat_raw + bu)\n",
        "\n",
        "        # Update hidden state with (1 - update gate) * hidden_t-1 + (update gate * h tilde):\n",
        "        hidden_new = (1 - u_gate) * hidden + u_gate * h_tilde\n",
        "        \n",
        "        return hidden_new\n",
        "    \n",
        "    def linear_head(self, input):\n",
        "        return self.W_h2o @ input + self.b_h20\n",
        "\n",
        "    def linear_attention(self, input):\n",
        "        return self.W_att @ input + self.ba\n",
        "\n",
        "    def linear_relu(self, input):\n",
        "        return self.W_rel @ input + self.brel\n",
        "\n",
        "    def backprop_update(self, optimizer) -> None:\n",
        "        \"\"\"Zero gradients, backpropogate via loss, and update params with optimizer\"\"\"\n",
        "        # ensure gradients are zerod\n",
        "        # for p in self.params:\n",
        "        #     p.grad = None\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # backprop\n",
        "        self.loss.backward()\n",
        "\n",
        "        # update\n",
        "        # for i, p in enumerate(self.params):\n",
        "        #     p.data += -lr * p.grad\n",
        "        optimizer.step()\n",
        "\n",
        "    def _count_params(self):\n",
        "        n_params = 0\n",
        "        for p in self.params:\n",
        "            n_params += p.nelement()\n",
        "        return n_params\n",
        "\n",
        "\n",
        "    def forward(self, x:torch.tensor, y:torch.tensor=None, teacher_forcing_ratio=0.0, max_length=100):\n",
        "        \"\"\"\n",
        "        Perform an entire forward pass of one sample to calculate outputs and calculate loss if y is provided.\n",
        "        Returns output_chars, loss.\n",
        "        \"\"\"\n",
        "\n",
        "        # Determine maximum length to predict for\n",
        "        if y is None:\n",
        "            target_length = max_length\n",
        "        else:\n",
        "            target_length = y.shape[0]\n",
        "            # y_ohe = torch.nn.functional.one_hot(y, num_classes=self.output_size)\n",
        "\n",
        "\n",
        "        # ENCODER\n",
        "        # Tensor to store the encoder gru's outputs at each timestep (as columns)\n",
        "        enc_outputs = torch.zeros((self.max_length, self.enc_hidden_size), device=self.device)\n",
        "        # Initialize hidden state with zeros\n",
        "        enc_hidden = self.init_hidden()\n",
        "\n",
        "        # Pass through X sequentially into the encoder and update hidden state\n",
        "        loss = 0\n",
        "        for t in range(x.shape[0]):\n",
        "            enc_hidden = self.encoder(hidden_prev=enc_hidden, x_tensor_t=x[t])\n",
        "            enc_outputs[t] = enc_hidden.squeeze(1)\n",
        "        \n",
        "        # encoder passes the finall hidden state (context vector) to simple decoder or attention decoder\n",
        "        # the attention decoder also uses the enc_outputs matrix (ie, it uses all of the hidden states produced in the loop above)\n",
        "\n",
        "        # DECODER\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False ##returns True if the float between [0, 1] is less than ratio\n",
        "        output_chrs = []\n",
        "        dec_hidden = enc_hidden ##last enc hidden state is the first context vector for simple decoder/first hidden state for attention decoder\n",
        "\n",
        "        # Use the final hidden state (context vector) and the start token to start the decoding and predict the next character in the sequence\n",
        "        # Repeat until the stop token is predicted or the target length is reached\n",
        "        input_chr = self.start_chr_ix \n",
        "        for t in range(target_length):\n",
        "            # SIMPLE\n",
        "            if self.dec_type==\"simple\":\n",
        "                # The last encoder hidden vector is \n",
        "                dec_hidden, logits, input_chr = self.simple_decoder(context_vector=dec_hidden, input_char_t=input_chr)\n",
        "                output_chrs.append(input_chr)\n",
        "            \n",
        "            # ATTENTION\n",
        "            if self.dec_type==\"attention\":\n",
        "                dec_hidden, logits, input_chr = self.attention_decoder(enc_outputs=enc_outputs, \n",
        "                                                                       prev_hidden=dec_hidden,\n",
        "                                                                       input_char_t=input_chr)  ##returns predicted character\n",
        "                output_chrs.append(input_chr)\n",
        "\n",
        "            if y is not None:\n",
        "                loss += torch.nn.functional.cross_entropy(logits.squeeze(), y[t])\n",
        "\n",
        "            if input_chr == self.stop_chr_ix:\n",
        "                break\n",
        "\n",
        "            if use_teacher_forcing:\n",
        "                # overwrite the predicted input_chr since we will give the model the true input chr\n",
        "                input_chr = y[t].item()\n",
        "        \n",
        "        # Save final loss for backpropagation through time\n",
        "        self.loss = loss\n",
        "\n",
        "        return output_chrs, loss\n",
        "    \n",
        "    def evaluate(self, english_text:str=\"hello\", level=\"word\"):\n",
        "        \"\"\"Forward passes english_txt + 'stop_chr' through the model. level is either 'word' or 'character'.\"\"\"\n",
        "        remove_punct = ''.join([p for p in string.punctuation if p not in \"'<\"])\n",
        "\n",
        "        if level==\"word\":\n",
        "            text = english_text+\" <\"\n",
        "            text = ''.join([c for c in text.lower() if c not in remove_punct])\n",
        "            input = torch.tensor([self.stoi[w] for w in text.split()], device=self.device)\n",
        "        elif level==\"character\":\n",
        "            text = english_text+\"<\"\n",
        "            input = torch.tensor([self.stoi[c] for c in text], device=self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for t in range(input.shape[0]):\n",
        "                output, loss = self.forward(input, y=None)\n",
        "\n",
        "        spaces=True\n",
        "        if level=='character': spaces=False\n",
        "        pred_transl, _ = self.decode_output(output,spaces=spaces)\n",
        "\n",
        "        # if check_google:\n",
        "        #     try:\n",
        "        #         translator = google_translator()\n",
        "        #         google_transl = translator.translate(english_text, lang_src='en', lang_tgt='fr')\n",
        "        #     except:\n",
        "        #         google_transl = \"Error accessing Google translate.\"\n",
        "        #     return pred_transl, google_transl\n",
        "        # else:\n",
        "\n",
        "        return pred_transl\n",
        "\n",
        "    def decode_output(self, output, label=None, spaces=False):\n",
        "        \"\"\"Returns predicted translation, true translation ( = None if label is None)\"\"\"\n",
        "        pred = []\n",
        "        truth = [] if label is not None else None\n",
        "        \n",
        "        # input = [itos[ix.item()] for ix in x]\n",
        "        for i in range(len(output)):\n",
        "            pred.append(self.itos[output[i]])\n",
        "        if label is not None:\n",
        "            for i in range(len(label)):\n",
        "                truth.append(self.itos[label[i].item()])\n",
        "\n",
        "        if spaces:\n",
        "            pred_transl = \" \".join(pred)\n",
        "            true_transl = \" \".join(truth) if label is not None else None\n",
        "        else:\n",
        "            pred_transl = \"\".join(pred)\n",
        "            true_transl = \"\".join(truth) if label is not None else None\n",
        "        return pred_transl, true_transl\n"
      ],
      "metadata": {
        "id": "bgrdyeegrXnv"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "u-g9x5n0uGZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CHARS = 30\n",
        "START_CHR = '>'\n",
        "STOP_CHR = '<'\n",
        "\n",
        "english, french = import_data(\"/content/gdrive/MyDrive/Colab/seq2seq_transl/eng-fra.txt\",\n",
        "                              max_english_chars=MAX_CHARS, max_french_chars=MAX_CHARS)"
      ],
      "metadata": {
        "id": "ye_rshX4UqXS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model can operate on the character level..."
      ],
      "metadata": {
        "id": "NbR3wM_J7eBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eng_chars = set(''.join(english))\n",
        "# fra_chars = set(''.join(french))\n",
        "all_chars = set(''.join(english + french))\n",
        "\n",
        "stoi = {s:i+2 for i, s in enumerate(all_chars)} ##create dictionary mapping from char to int\n",
        "stoi[START_CHR] = 1\n",
        "stoi[STOP_CHR] = 0\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "\n",
        "\n",
        "print(len(english))\n",
        "print(len(all_chars))\n",
        "print(\"max english length = \", len(max(english, key=len)), \"chars\")\n",
        "print(\"max french length = \", len(max(french, key=len)), \"chars\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvK3XTpfresu",
        "outputId": "8358fb6d-6978-42ba-ba0a-08a00a444c72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51177\n",
            "98\n",
            "max english length =  30 chars\n",
            "max french length =  30 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or the word level."
      ],
      "metadata": {
        "id": "Qi3hf0fp7gnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KEEP_PUNCT = \"'-\"\n",
        "remove_punct = ''.join([p for p in string.punctuation if p not in KEEP_PUNCT])\n",
        "# join all phrases with space in between\n",
        "all_words = ' '.join(english + french)\n",
        "# remove punctuation characters except for those not in remove_punct\n",
        "all_words = ''.join([c for c in all_words if c not in remove_punct])\n",
        "\n",
        "# create mapping from string to int\n",
        "wtoi = {word:i+2 for i, word in enumerate( sorted(set(all_words.lower().split())) )}\n",
        "wtoi[START_CHR] = 1\n",
        "wtoi[STOP_CHR] = 0\n",
        "\n",
        "itow = {i:w for w, i in wtoi.items()}"
      ],
      "metadata": {
        "id": "E3Z9mqv71ryD"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total words in vocab =\", len(wtoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMge4zch6k9U",
        "outputId": "835b5384-c72c-4e01-bb71-fbe66f793f93"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words in vocab = 19222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqkjyUHLol_h"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now generate inputs from the text data and the text to int mappings."
      ],
      "metadata": {
        "id": "QHVKxqXn7ji5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_SAMPLES = 1000 #len(english)\n",
        "Xs, Ys = words_to_word_data(english[:N_SAMPLES], french[:N_SAMPLES], \n",
        "                          wtoi, stop_char=STOP_CHR, \n",
        "                          device=device,\n",
        "                          keep_punct=KEEP_PUNCT)"
      ],
      "metadata": {
        "id": "HqpDJokvzAcC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "xflO0BTFXnKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And initialize an encoder-decoder model."
      ],
      "metadata": {
        "id": "7codH-lz7p4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "n_words = len(wtoi)\n",
        "hidden_size = 128\n",
        "emb_dim = 64\n",
        "\n",
        "model = TranslGRU(vocab_size=n_words,\n",
        "                  enc_embed_dim=emb_dim,\n",
        "                  dec_embed_dim=emb_dim,\n",
        "                  dec_type=\"attention\",\n",
        "                  hidden_size=hidden_size,\n",
        "                  max_length=MAX_CHARS,\n",
        "                  stoi_mapping=wtoi, \n",
        "                  start_chr=START_CHR, stop_chr=STOP_CHR\n",
        "                  )\n",
        "model.init_weights(device=device)\n",
        "\n",
        "print(\"MODEL PARAMETERS:\", model.n_parameters)\n",
        "print(\"training samples:\", len(Xs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vPEFxM0ufLc",
        "outputId": "22dbc507-ad01-4b43-ec48-11894b9e8a02"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL PARAMETERS: 5106164\n",
            "training samples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, p in zip(model.param_names, model.params):\n",
        "    print(f\"| {n}  | {p.shape[0], p.shape[1]} | n =  {p.nelement():,} | {p.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlvvrZvtbSSN",
        "outputId": "531140f8-20d9-4850-9a79-af5c6d3a24b5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| enc_embed  | (19222, 64) | n =  1,230,208 | cuda:0\n",
            "| enc_W_reset  | (128, 192) | n =  24,576 | cuda:0\n",
            "| enc_br  | (128, 1) | n =  128 | cuda:0\n",
            "| enc_W_update  | (128, 192) | n =  24,576 | cuda:0\n",
            "| enc_bu  | (128, 1) | n =  128 | cuda:0\n",
            "| enc_W_htilde  | (128, 192) | n =  24,576 | cuda:0\n",
            "| W_att  | (30, 192) | n =  5,760 | cuda:0\n",
            "| ba  | (30, 1) | n =  30 | cuda:0\n",
            "| W_rel  | (64, 192) | n =  12,288 | cuda:0\n",
            "| brel  | (64, 1) | n =  64 | cuda:0\n",
            "| dec_embed  | (19222, 64) | n =  1,230,208 | cuda:0\n",
            "| dec_W_reset  | (128, 192) | n =  24,576 | cuda:0\n",
            "| dec_br  | (128, 1) | n =  128 | cuda:0\n",
            "| dec_W_update  | (128, 192) | n =  24,576 | cuda:0\n",
            "| dec_bu  | (128, 1) | n =  128 | cuda:0\n",
            "| dec_W_htilde  | (128, 192) | n =  24,576 | cuda:0\n",
            "| W_h2o  | (19222, 128) | n =  2,460,416 | cuda:0\n",
            "| b_h20  | (19222, 1) | n =  19,222 | cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try training the model on one example."
      ],
      "metadata": {
        "id": "JXJ0Ge5u8cSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing model on a single phrase\n",
        "optimizer = torch.optim.Adam(model.params, lr=0.01)\n",
        "# (takes more iterations for longer phrases to be learned)\n",
        "for _ in range(200):\n",
        "    s = 999\n",
        "\n",
        "    x, y = Xs[s], Ys[s]\n",
        "\n",
        "    output, loss = model.forward(x, y, teacher_forcing_ratio=0)\n",
        "    model.backprop_update(optimizer)\n",
        "\n",
        "print(loss.item() / len(y))\n",
        "guess, true = model.decode_output(output, label=y, spaces=True)\n",
        "print(\"Guess:\", guess)\n",
        "print(\"True:\", true)\n",
        "print(\"English:\", ' '.join([itow[i.item()] for i in x]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "las1LQjbumZZ",
        "outputId": "06a7e5a1-47e1-486a-a6eb-97e73c133b74"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.013236501812934875\n",
            "Guess: j'ai reçu de l'aide <\n",
            "True: j'ai reçu de l'aide <\n",
            "English: i had help <\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for some more serious training..."
      ],
      "metadata": {
        "id": "iDiqRqsxc2rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset weights\n",
        "model.init_weights(device, seed=10418)\n",
        "optimizer = torch.optim.Adam(model.params, lr=3e-4)\n",
        "\n",
        "TF_RATIO = 0.5\n",
        "print_every = 1\n",
        "plot_every = 1\n",
        "epochs = 20\n",
        "log_file = '/content/gdrive/MyDrive/Colab/seq2seq_transl/train-log.txt'\n",
        "\n",
        "loss_list = []\n",
        "open(log_file, 'w').close() #empty the log file"
      ],
      "metadata": {
        "id": "zF5IemT4uu5p"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert (Xs[0].device == device) & (Ys[0].device == device), f\"put data on {device}\"\n",
        "\n",
        "strt = time.time()\n",
        "for epoch in range(1, epochs+1):\n",
        "    ep_loss = 0\n",
        "    sample_ix = [i for i in range(0, N_SAMPLES)]\n",
        "    random.shuffle(sample_ix)\n",
        "\n",
        "    # iterate through every sample in the training data\n",
        "    for sample in sample_ix:\n",
        "        x, y = Xs[sample], Ys[sample] ##already on device\n",
        "        output, loss = model.forward(x, y, teacher_forcing_ratio=TF_RATIO)\n",
        "        ep_loss += loss.item()\n",
        "\n",
        "        model.backprop_update(optimizer)\n",
        "    \n",
        "    # write epoch loss to log\n",
        "    with open(log_file, 'a') as f:\n",
        "      f.write(f'epoch {epoch}; loss {ep_loss / N_SAMPLES} \\n')\n",
        "\n",
        "    # print\n",
        "    if epoch % print_every == 0:\n",
        "        stp = time.time()\n",
        "        guess, true = model.decode_output(output, label=y, spaces=True) ##use the last training sample as an example\n",
        "\n",
        "        print(f\"({epoch}/{epochs}) loss = {round(ep_loss/N_SAMPLES, 6)}\", end=\" \")\n",
        "        print(f\"(elapsed: {round(stp-strt, 3)}s)\")\n",
        "        print(\"GUESS:\", guess, end=\"   \")\n",
        "        print(\"TRUTH:\", true, end=\"   \")\n",
        "        print(\"ENG:\", ' '.join([itow[i.item()] for i in x]))\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        loss_list.append(ep_loss/N_SAMPLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJIb4I_kuyRn",
        "outputId": "5bdad33c-4bd8-4d8d-8a27-4f67584ec8d0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1/20) loss = 6.895785 (elapsed: 8.911s)\n",
            "GUESS: nous avons <   TRUTH: nous discutâmes <   ENG: we talked <\n",
            "(2/20) loss = 6.701077 (elapsed: 17.812s)\n",
            "GUESS: je suis prêt <   TRUTH: je suis dur à cuire <   ENG: i'm tough <\n",
            "(3/20) loss = 6.580071 (elapsed: 26.738s)\n",
            "GUESS: soyez fait <   TRUTH: soyez satisfaites <   ENG: be content <\n",
            "(4/20) loss = 6.486535 (elapsed: 35.659s)\n",
            "GUESS: assieds-toi <   TRUTH: calmez-vous <   ENG: cool down <\n",
            "(5/20) loss = 6.306553 (elapsed: 44.539s)\n",
            "GUESS: à <   TRUTH: est-ce sérieux <   ENG: seriously <\n",
            "(6/20) loss = 6.122873 (elapsed: 53.36s)\n",
            "GUESS: qui est <   TRUTH: qui est-ce <   ENG: who is it <\n",
            "(7/20) loss = 5.930785 (elapsed: 62.29s)\n",
            "GUESS: je me suis pas <   TRUTH: je me fais vraiment du souci <   ENG: i do worry <\n",
            "(8/20) loss = 5.879765 (elapsed: 71.252s)\n",
            "GUESS: je ferai <   TRUTH: je passerai <   ENG: i'll pass <\n",
            "(9/20) loss = 5.588598 (elapsed: 80.214s)\n",
            "GUESS: il est <   TRUTH: il a laissé tomber <   ENG: he quit <\n",
            "(10/20) loss = 5.563114 (elapsed: 89.111s)\n",
            "GUESS: je suis fainéante <   TRUTH: je suis paresseuse <   ENG: i am lazy <\n",
            "(11/20) loss = 5.429677 (elapsed: 98.064s)\n",
            "GUESS: je suis certain <   TRUTH: je suis paresseux <   ENG: i'm lazy <\n",
            "(12/20) loss = 5.236913 (elapsed: 107.001s)\n",
            "GUESS: je suis occupé <   TRUTH: je suis malade <   ENG: i am sick <\n",
            "(13/20) loss = 5.081064 (elapsed: 115.986s)\n",
            "GUESS: est-ce que <   TRUTH: est-ce que c'est vous <   ENG: is it you <\n",
            "(14/20) loss = 5.014845 (elapsed: 125.021s)\n",
            "GUESS: ne a pas pas <   TRUTH: ne vous précipitez pas <   ENG: don't rush <\n",
            "(15/20) loss = 4.990831 (elapsed: 133.998s)\n",
            "GUESS: je suis timide <   TRUTH: je suis restée <   ENG: i stayed <\n",
            "(16/20) loss = 4.849234 (elapsed: 142.984s)\n",
            "GUESS: soyez sérieux <   TRUTH: soyez sérieuse <   ENG: be serious <\n",
            "(17/20) loss = 4.663729 (elapsed: 151.968s)\n",
            "GUESS: réveillez-vous <   TRUTH: réveille-toi <   ENG: wake up <\n",
            "(18/20) loss = 4.626519 (elapsed: 161.048s)\n",
            "GUESS: nous avons timides <   TRUTH: nous sommes tombés d'accord <   ENG: we agreed <\n",
            "(19/20) loss = 4.414995 (elapsed: 170.055s)\n",
            "GUESS: excellent <   TRUTH: génial <   ENG: terrific <\n",
            "(20/20) loss = 4.34358 (elapsed: 179.105s)\n",
            "GUESS: nous sommes tombés <   TRUTH: nous sommes timides <   ENG: we're shy <\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "with open(log_file, \"r\") as f:\n",
        "  for line in f:\n",
        "    line = line.strip()\n",
        "    losses.append( float(line.split()[-1]) )\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f\"Loss every {plot_every} epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dCM81qmq7RKZ",
        "outputId": "5397d178-e689-45f9-ba80-6d03ccd0586a"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_grad_flow_basic(model.params, model.param_names, y_ax_max=\"max_average\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "WlUHtZMd7ZqH",
        "outputId": "81d969ad-eeff-4535-90aa-2d7a101a60e3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "Ay1K04mSlZ-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(\"Deep learning is fun\", level=\"word\") ##my output is 'trouve un boulot <' which actually translates to 'find a job'... damn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-0wfYlHylbtU",
        "outputId": "062b4dd9-b6c4-4912-ae40-0138f0b7d3d4"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trouve un boulot <'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    }
  ]
}